#!/usr/bin/env python3
"""
compress_rf_probabilities.py
----------------------------
Post-processes probability map tiles generated by inference_rf_on_tiles.py.
Reads 2-band probability tiles (uint8, 0-255), extracts the probability
for the first class, and saves it as a compressed single-band GeoTIFF.
The output filename indicates the class name corresponding to the saved probability.
"""

import sys
import argparse
import logging
import joblib
import numpy as np
import rasterio
from rasterio.windows import Window
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm
from pathlib import Path
import time
import os

# --- Configuration & Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("compress_rf_probabilities")

DEFAULT_MAX_WORKERS = 4

# --- Worker Function ---
def process_tile(input_tile_path: Path, output_dir: Path, class_name_band0: str, compression_opts: dict):
    """Processes a single probability tile."""
    pid = os.getpid()
    try:
        logger.debug(f"[PID {pid}] Processing tile: {input_tile_path.name}")
        
        with rasterio.open(input_tile_path) as src:
            profile = src.profile
            if profile['count'] != 2:
                logger.warning(f"[PID {pid}] Tile {input_tile_path.name} does not have 2 bands (found {profile['count']}). Skipping.")
                return f"Skipped (wrong band count): {input_tile_path.name}"

            # Read only the first band
            prob_band0_data = src.read(1)

            # Update profile for single-band output
            profile.update({
                'count': 1,
                'dtype': 'uint8', # Keep uint8
                'nodata': profile.get('nodata'), # Keep original nodata if any
                'compress': compression_opts.get('compress', 'lzw'),
                'predictor': compression_opts.get('predictor', 2),
                'tiled': compression_opts.get('tiled', True),
                'blockxsize': compression_opts.get('blockxsize', 256),
                'blockysize': compression_opts.get('blockysize', 256),
                'BIGTIFF': compression_opts.get('BIGTIFF', 'YES')
            })
            
            # Construct output filename
            output_filename = f"{input_tile_path.stem}_prob_{class_name_band0}.tif"
            output_tile_path = output_dir / output_filename

            # Write the single band to the new file
            with rasterio.open(output_tile_path, 'w', **profile) as dst:
                dst.write(prob_band0_data, 1)

        return f"Successfully processed: {output_filename}"

    except Exception as e:
        logger.error(f"[PID {pid}] Failed processing {input_tile_path.name}: {e}", exc_info=True)
        return f"Failed: {input_tile_path.name}"


# --- Main Execution ---
def main():
    parser = argparse.ArgumentParser(description="Compress 2-band RF probability tiles to single-band tiles.")
    parser.add_argument("--input-dir", type=str, required=True,
                        help="Directory containing input 2-band probability tiles (GeoTIFF).")
    parser.add_argument("--output-dir", type=str, required=True,
                        help="Directory to save the output single-band probability tiles (GeoTIFF).")
    parser.add_argument("--model", type=str, required=True,
                        help="Path to the trained RandomForest model (.joblib file) used to generate the probabilities. Needed to determine class names.")
    parser.add_argument("--workers", type=int, default=DEFAULT_MAX_WORKERS,
                        help=f"Number of parallel workers (default: {DEFAULT_MAX_WORKERS}). Ignored if --test is used.")
    parser.add_argument("-v", "--verbose", action="store_true",
                        help="Enable debug logging.")
    parser.add_argument("--test", action="store_true",
                        help="Run in test mode: process only the first tile found.")

    args = parser.parse_args()

    if args.verbose:
        logger.setLevel(logging.DEBUG)
        for handler in logger.handlers:
            handler.setLevel(logging.DEBUG)
        logger.debug("Debug logging enabled.")

    start_time = time.time()

    try:
        input_dir = Path(args.input_dir)
        output_dir = Path(args.output_dir)
        model_path = Path(args.model)

        if not input_dir.is_dir():
            logger.error(f"Input directory not found: {input_dir}")
            sys.exit(1)
        if not model_path.exists():
             logger.error(f"Model file not found: {model_path}")
             sys.exit(1)

        output_dir.mkdir(parents=True, exist_ok=True)

        # Find all input GeoTIFF tiles
        input_files = list(input_dir.glob('*.tif*'))
        if not input_files:
             logger.error(f"No .tif or .tiff files found in {input_dir}")
             sys.exit(1)

        if args.test:
            logger.info("--- TEST MODE ENABLED --- Processing only the first tile.")
            input_files = input_files[:1] # Keep only the first file
            if not input_files: # Should not happen if previous check passed, but safety first
                 logger.error("No tiles found to process even in test mode.")
                 sys.exit(1)
            logger.info(f"Test tile: {input_files[0].name}")
            args.workers = 1 # Force single worker for test mode

        logger.info(f"Found {len(input_files)} input tiles in {input_dir} to process.")

        # Load model to get class names
        logger.info(f"Loading model from: {model_path} to determine class order.")
        model = joblib.load(model_path)
        if not hasattr(model, 'classes_'):
            logger.error(f"Model loaded from {model_path} does not have a 'classes_' attribute. Cannot determine class names.")
            sys.exit(1)
        
        model_classes = list(model.classes_)
        logger.info(f"Model classes found: {model_classes}")
        if len(model_classes) != 2:
             logger.warning(f"Model has {len(model_classes)} classes, not 2. This script assumes the first band corresponds to the first class '{model_classes[0]}'.")
             # It might be safer to exit here if strict 2-class assumption is needed
             # sys.exit(1) 
        
        class_name_band0 = str(model_classes[0]).replace(" ", "_").lower() # Make filename-safe
        logger.info(f"Saving probability for class: '{class_name_band0}' (the first class in model.classes_)")

        # Compression options (could be made configurable)
        compression_opts = {
            'compress': 'DEFLATE',
            'zlevel': 9,
            'predictor': 2,
            'tiled': True,
            'blockxsize': 256,
            'blockysize': 256,
            'BIGTIFF': 'YES'
        }
        logger.info(f"Using compression options: {compression_opts}")

        # --- Parallel Processing ---
        processing_desc = "Compressing Tile" if args.test else "Compressing Tiles"
        logger.info(f"Starting processing of {len(input_files)} tile(s) with {args.workers} worker(s).")
        results = []
        with ProcessPoolExecutor(max_workers=args.workers) as executor:
            futures = [executor.submit(process_tile, tile_path, output_dir, class_name_band0, compression_opts)
                       for tile_path in input_files]

            for future in tqdm(as_completed(futures), total=len(input_files), desc=processing_desc):
                 results.append(future.result())

        end_time = time.time()
        logger.info(f"Processing finished in {end_time - start_time:.2f} seconds.")

        # Log summary
        success_count = sum(1 for res in results if "Successfully" in res)
        skipped_count = sum(1 for res in results if "Skipped" in res)
        failure_count = len(results) - success_count - skipped_count
        logger.info(f"Processing Summary: Success={success_count}, Skipped={skipped_count}, Failures={failure_count}")

    except FileNotFoundError as e:
        logger.error(f"Setup error - File not found: {e}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main() 